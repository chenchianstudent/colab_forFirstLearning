{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER-Ensemble_test02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su3Yb9375VnQ"
      },
      "source": [
        "## 載入&重設定必要物件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL5WpjjecGJ9"
      },
      "source": [
        "!pip install tensorflow-gpu==1.13.1\n",
        "!pip install conlleval==0.1\n",
        "#!pip install jieba==0.39\n",
        "!pip install git+https://github.com/APCLab/jieba-tw.git\n",
        "!pip install numpy==1.17.3\n",
        "!pip install requests==2.22.0\n",
        "!pip install tornado==6.0.3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1YJPUqnW8Mm"
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hYGDFrVYQ8k"
      },
      "source": [
        "!pip install tensorflow==1.13.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MedjhnfoXcjs"
      },
      "source": [
        "!pip install keras==2.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtALQRt05jm_"
      },
      "source": [
        "## 與雲端做連接"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTZGU-ZLRFqW",
        "outputId": "f5ddcdcd-f44e-45de-cc27-7018055aa5b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 如果出現了長條型的可輸入單元格 代表你曾經 授權過了 可以直接跳到下一格\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5udMmFhRRT9B",
        "outputId": "9d067bc1-cb6a-4428-d6e1-fde4f29c73a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 指定Google Drive雲端硬盤的根目錄，名為drive\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_QpNVGJRT_e"
      },
      "source": [
        "import os\n",
        "os.chdir(\"drive\")\n",
        "if(\"Colab Notebooks\" in os.listdir()):\n",
        "  os.chdir(\"Colab Notebooks\")\n",
        "else:\n",
        "  os.mkdir(\"Colab Notebooks\")\n",
        "  os.chdir(\"Colab Notebooks\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7Z2sJmMRUB6",
        "outputId": "6e70d7e6-2eb1-43b2-9d3f-05260c5041ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105021007_homework4.ipynb  Ex8_1_Stock_Price_Prediction.ipynb\n",
            "bilstm4ner\t\t   NER-Ensemble_test02.ipynb\n",
            "bilstm_ner_tf\t\t   NerModel_test01.ipynb\n",
            "CNN_minst_test.ipynb\t   resemable-learning_test.ipynb\n",
            "Ensemble_test.ipynb\t   titanic\n",
            "Ex6-1-MNIST.ipynb\t   Titanic_UseEnsemble_test.ipynb\n",
            "Ex6-2-Fashion-MNIST.ipynb  Untitled0.ipynb\n",
            "Ex7-1-CNN.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue-w3dVZ5wAF"
      },
      "source": [
        "## 主要內容"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuoeYTIVRUET"
      },
      "source": [
        "# 数据读取与计算\n",
        "import pandas as  pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 数据预处理与模型选择\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report\n",
        "import itertools\n",
        "\n",
        "# 随机森林与SVM\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from scipy import stats\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaEnw-h-SHdj",
        "outputId": "cc41025b-5c01-4bf5-dbb3-6f8c8cf69cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#　%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHydYMAyRUG0",
        "outputId": "44159a60-6c66-4552-9cf6-01488d0a6e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#載入bilstm4ner的模型，因為有\"bilstm_3000\",\"bilstm_4000\",\"bilstm_5000\"這三種模型，不知道要選哪種，因此選個數字最大的\n",
        "from keras.models import load_model\n",
        "\n",
        "# !pip install git+https://www.github.com/keras-team/keras-contrib.git   (\"\"\"No module named 'keras_contrib'\"\"\"解決辦法)\n",
        "# tensorflow指定1.13.1 keras指定2.2.0 keras-contrib指定2.0.8 版本其中一個錯誤會無法讀入模型\n",
        "from keras_contrib.layers.crf import CRF, crf_loss, crf_viterbi_accuracy\n",
        "model_path = 'bilstm4ner/model/bilstm_5000.h5'\n",
        "modelPart1 = load_model(model_path, custom_objects={\"CRF\": CRF, 'crf_loss': crf_loss,\n",
        "                          'crf_viterbi_accuracy': crf_viterbi_accuracy})\n",
        "for layer in modelPart1.layers:\n",
        "\t\t\tlayer.trainable = False\n",
        "#new_model = tf.keras.models.load_model('C:/Users/danie/NER-Ensemble/bilstm_ner_tf/data_path_save/1521112368/checkpoints')\n",
        "# model = create_model()\n",
        "# model.load_weights('C:/Users/danie/NER-Ensemble/bilstm_ner_tf/data_path_save/1521112368/checkpoints')\n",
        "# model.load_weights('bilstm_ner_tf/data_path_save/1521112368/checkpoints/model-31680.data-00000-of-00001')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3363: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFsdEjaz6cvg",
        "outputId": "2d40b461-5fd0-4125-d250-a65fb2172b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "modelPart1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "masking_1 (Masking)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 300, 300)          1965600   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 300, 256)          439296    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 300, 256)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 300, 256)          394240    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 300, 256)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 300, 128)          164352    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 300, 128)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 300, 128)          98816     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 300, 128)          0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 300, 64)           8256      \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 300, 33)           2145      \n",
            "_________________________________________________________________\n",
            "crf_1 (CRF)                  (None, 300, 33)           2277      \n",
            "=================================================================\n",
            "Total params: 3,074,982\n",
            "Trainable params: 3,074,982\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ncHKr3Vf5Oy",
        "outputId": "66c036a4-2f2d-4bac-d90c-2c23a81ffc0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "model_path = 'bilstm4ner/model/bilstm_3000.h5'\n",
        "modelPart2 = load_model(model_path, custom_objects={\"CRF\": CRF, 'crf_loss': crf_loss,\n",
        "                          'crf_viterbi_accuracy': crf_viterbi_accuracy})\n",
        "for layer in modelPart2.layers:\n",
        "\t\t\tlayer.trainable = False\n",
        "modelPart2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "masking_1 (Masking)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 300, 300)          1965600   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 300, 256)          439296    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 300, 256)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 300, 256)          394240    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 300, 256)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 300, 128)          164352    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 300, 128)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 300, 128)          98816     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 300, 128)          0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 300, 64)           8256      \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 300, 33)           2145      \n",
            "_________________________________________________________________\n",
            "crf_1 (CRF)                  (None, 300, 33)           2277      \n",
            "=================================================================\n",
            "Total params: 3,074,982\n",
            "Trainable params: 3,074,982\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WvxQNTN4vEp",
        "outputId": "ffbaa4b7-bab9-4506-9784-5dd7d9275e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "new_model = keras.models.load_model('bilstm_ner_tf/data_path_save/1521112368/checkpoints')\n",
        "#modelPart1.load_weights('bilstm_ner_tf/data_path_save/1521112368/checkpoints/model-31680.data-00000-of-00001')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-56c5c4f91912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bilstm_ner_tf/data_path_save/1521112368/checkpoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#modelPart1.load_weights('bilstm_ner_tf/data_path_save/1521112368/checkpoints/model-31680.data-00000-of-00001')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    221\u001b[0m   \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (file read failed: time = Tue Jul 28 08:27:43 2020\n, filename = 'bilstm_ner_tf/data_path_save/1521112368/checkpoints', file descriptor = 56, errno = 21, error message = 'Is a directory', buf = 0x7ffd67ced390, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofd3xIO2RUJG"
      },
      "source": [
        "modelsEnsemble = [modelPart1, modelPart2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCq3OtJozkjg"
      },
      "source": [
        "###暫時先用bilstm_3000和5000這兩個模型做測試\n",
        "\n",
        "import pickle\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from mlxtend.classifier import StackingCVClassifier\n",
        "lr = LogisticRegression(n_jobs=-1, C=8)  # meta classifier\n",
        "sclf = StackingCVClassifier(classifiers=[modelPart1, modelPart2], \n",
        "               #use_probas=True,\n",
        "               #average_probas=False,\n",
        "               meta_classifier=lr)\n",
        "\n",
        "#sclf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNp_NUHqcWPy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6WwXxfBzUVU"
      },
      "source": [
        "## 參考code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EVh58N_RULd"
      },
      "source": [
        "def ensemble(modelsEnsemble, model_input):\n",
        "\n",
        "\n",
        "    outputs = [model.outputs[0] for model in modelsEmsemble]\n",
        "\n",
        "    y = Average()(outputs)\n",
        "\n",
        "\n",
        "    model = Model(model_input, y, name='ensemble')\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "ensemble_model = ensemble(modelsEnsemble, model_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKlmBIy_RUNr"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import pickle\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from mlxtend.classifier import StackingCVClassifier\n",
        "\n",
        "with open('../data/training_df.pkl', 'rb') as f:\n",
        "    df = pickle.load(f)\n",
        "with open(r'../data/selected_feat_names.pkl', 'rb') as f:\n",
        "    selected_feat_names = pickle.load(f)\n",
        "print(\"data loaded\")\n",
        "\n",
        "# train on full data set\n",
        "y = df[\"attack_type\"].values\n",
        "X = df[selected_feat_names].values\n",
        "\n",
        "xgb = XGBClassifier(learning_rate =0.5,n_estimators=300,max_depth=5,gamma=0,subsample=0.8,)\n",
        "rfc = RandomForestClassifier(n_jobs=-1, n_estimators=35, criterion=\"entropy\")\n",
        "etc = ExtraTreesClassifier(n_jobs=-1, n_estimators=5, criterion=\"entropy\")\n",
        "lr = LogisticRegression(n_jobs=-1, C=8)  # meta classifier\n",
        "\n",
        "sclf = StackingCVClassifier(classifiers=[xgb, rfc, etc], meta_classifier=lr, use_probas=True, n_folds=3, verbose=3)\n",
        "\n",
        "sclf.fit(X, y)\n",
        "print(\"training finished\")\n",
        "\n",
        "# save model for later predicting\n",
        "with open(r'../data/stacking.pkl', 'wb') as f:\n",
        "    pickle.dump(sclf, f)\n",
        "print(\"model dumped\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T55en9HLnkNA"
      },
      "source": [
        "# https://www.itread01.com/content/1542136503.html\n",
        "# https://www.itread01.com/content/1548189913.html\n",
        "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3],\n",
        "                          use_probas=True,\n",
        "                          average_probas=False,\n",
        "                          meta_classifier=lr)\n",
        "\n",
        "# 引數：\n",
        "\n",
        "# classifiers : 基分類器，陣列形式，[cl1, cl2, cl3]. 每個基分類器的屬性被儲存在類屬性 self.clfs_.\n",
        "# meta_classifier : 目標分類器，即將前面分類器合起來的分類器\n",
        "# use_probas : bool (default: False) ，如果設定為True， 那麼目標分類器的輸入就是前面分類輸出的類別概率值而不是類別標籤\n",
        "# average_probas : bool (default: False)，用來設定上一個引數當使用概率值輸出的時候是否使用平均值。\n",
        "# verbose : int, optional (default=0)。用來控制使用過程中的日誌輸出，當 verbose = 0時，什麼也不輸出， verbose = 1，輸出迴歸器的序號和名字。verbose = 2，輸出詳細的引數資訊。verbose > 2, 自動將verbose設定為小於2的，verbose -2.\n",
        "# use_features_in_secondary : bool (default: False). 如果設定為True，那麼最終的目標分類器就被基分類器產生的資料和最初的資料集同時訓練。如果設定為False，最終的分類器只會使用基分類器產生的資料訓練。\n",
        "\n",
        "# 屬性：\n",
        "# clfs_ : 每個基分類器的屬性，list, shape 為 [n_classifiers]。\n",
        "# meta_clf_ : 最終目標分類器的屬性\n",
        "\n",
        "# 方法：\n",
        "\n",
        "# fit(X, y)\n",
        "# fit_transform(X, y=None, fit_params)\n",
        "# get_params(deep=True)，如果是使用sklearn的GridSearch方法，那麼返回分類器的各項引數。\n",
        "# predict(X)\n",
        "# predict_proba(X)\n",
        "# score(X, y, sample_weight=None)， 對於給定資料集和給定label，返回評價accuracy\n",
        "# set_params(params)，設定分類器的引數，params的設定方法和sklearn的格式一樣"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0OEkSgVXjjC"
      },
      "source": [
        "#https://ithelp.ithome.com.tw/articles/10187452\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import cross_validation, ensemble, preprocessing, metrics\n",
        "\n",
        "# 載入資料\n",
        "url = \"https://storage.googleapis.com/2017_ithome_ironman/data/kaggle_titanic_train.csv\"\n",
        "titanic_train = pd.read_csv(url)\n",
        "\n",
        "# 填補遺漏值\n",
        "age_median = np.nanmedian(titanic_train[\"Age\"])\n",
        "new_Age = np.where(titanic_train[\"Age\"].isnull(), age_median, titanic_train[\"Age\"])\n",
        "titanic_train[\"Age\"] = new_Age\n",
        "\n",
        "# 創造 dummy variables\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "encoded_Sex = label_encoder.fit_transform(titanic_train[\"Sex\"])\n",
        "\n",
        "# 建立訓練與測試資料\n",
        "titanic_X = pd.DataFrame([titanic_train[\"Pclass\"],\n",
        "                         encoded_Sex,\n",
        "                         titanic_train[\"Age\"]\n",
        "]).T\n",
        "titanic_y = titanic_train[\"Survived\"]\n",
        "train_X, test_X, train_y, test_y = cross_validation.train_test_split(titanic_X, titanic_y, test_size = 0.3)\n",
        "\n",
        "# 建立 bagging 模型\n",
        "bag = ensemble.BaggingClassifier(n_estimators = 100)\n",
        "bag_fit = bag.fit(train_X, train_y)\n",
        "\n",
        "# 預測\n",
        "test_y_predicted = bag.predict(test_X)\n",
        "\n",
        "# 績效\n",
        "accuracy = metrics.accuracy_score(test_y, test_y_predicted)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}